{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting algorithms in PyAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document describes the algorithmic aspects of time series forecasting in PyAF. \n",
    "We will describe:\n",
    "1. The overall algorithm\n",
    "2. The detail of the signal decomposition\n",
    "3. The machine learning aspects\n",
    "4. Advanced usage/control of the algorithms.\n",
    "5. Hierarchical forecasting.\n",
    "\n",
    "Warning : This document ins intended for advanced uses of PyAF. The aspects described here are not useful in a typical forecasting use case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Algorithmic Choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyAF uses a machine learning approach to forecasting. A lot of time series models are generated and their forecasting quality is compared on a validation dataset (most recent part of the whole signal). \n",
    "To summarize, PyAF is performing a competition between a large set of possible models/hypothesis and selecting the best to perform the final forecast.\n",
    "\n",
    "the models used/tested in PyAF are signal decompositions generated on the fly internally. An additive signal decomposition is the sum of a **trend** (long term) , **periodic** and an **irregular** component as described in http://en.wikipedia.org/wiki/Decomposition_of_time_series\n",
    "\n",
    "PyAF generates tens of possible decomposition for the input signal and outputs the best. One can control the amount/types of decompositions, enable/disable such of such component,  and review the performance of each decomposition internally.\n",
    "\n",
    "In addition to the decomposition , PyAF allows a whole set of possible **signal transformations** performed in a pre-processing phase (before decomposition) and a  post-processing step (after forecasting).\n",
    "\n",
    "PyAF performs the forecasting task of a signal $X_t$ in three steps described below:\n",
    "\n",
    "1. Signal Transformation : $$ Y_t = \\phi(X_t) $$\n",
    "2. Decomposition of the transformed signal : $$ \\hat{Y_t} = T_t + C_t + I_t $$\n",
    "3. Back transformation of the forecast : $$ \\hat{X_t}  = \\phi^{-1}(\\hat{Y_t}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Decompositions with PyAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyAF supports the following operations :\n",
    "\n",
    "lKnownTransformations = ['None', 'Difference', 'RelativeDifference','Integration', 'BoxCox', 'Quantization', 'Logit', 'Fisher', 'Anscombe'];\n",
    "\n",
    "lKnownTrends = ['ConstantTrend', 'Lag1Trend', 'LinearTrend', 'PolyTrend','MovingAverage', 'MovingMedian'];\n",
    "\n",
    "lKnownPeriodics = ['NoCycle', 'BestCycle',\n",
    "                   'Seasonal_MonthOfYear' ,\n",
    "                   'Seasonal_Second' ,\n",
    "                   'Seasonal_Minute' ,\n",
    "                   'Seasonal_Hour' ,\n",
    "                   'Seasonal_HourOfWeek' ,\n",
    "                   'Seasonal_TwoHourOfWeek' ,\n",
    "                   'Seasonal_ThreeHourOfWeek' ,\n",
    "                   'Seasonal_FourHourOfWeek' ,\n",
    "                   'Seasonal_SixHourOfWeek' ,\n",
    "                   'Seasonal_EightHourOfWeek' ,\n",
    "                   'Seasonal_TwelveHourOfWeek' ,\n",
    "                   'Seasonal_DayOfWeek' ,\n",
    "                   'Seasonal_DayOfMonth',\n",
    "                   'Seasonal_DayOfYear',\n",
    "                   'Seasonal_WeekOfMonth',\n",
    "                   'Seasonal_DayOfNthWeekOfMonth',\n",
    "                   'Seasonal_WeekOfYear']\n",
    "\n",
    "\n",
    "lKnownAutoRegressions = ['NoAR' , 'AR' , 'ARX' , 'SVR', 'SVRX', 'MLP' , 'LSTM' , 'XGB' , 'XGBX' , 'CROSTON', 'LGB', 'LGBX'];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "1. None : $$Y_t = \\phi(X_t) = X_t $$\n",
    "2. Difference : $$Y_t =  \\phi(X_t) = X_t  - X_{t-1} $$\n",
    "3. Relative Difference : $$Y_t =  \\phi(X_t) = \\frac{X_t  - X_{t-1}}{X_{t-1}} $$\n",
    "4. Integration : $$Y_t =  \\phi(X_t) = \\sum_{s=0}^{s=t} X_s $$\n",
    "\n",
    "Optional Transformations:\n",
    "\n",
    "5. BoxCox : $$Y_t =  \\phi(X_t) = \\frac{X_t^\\lambda - 1}{\\lambda} $$\n",
    "6. Quantization : $$Y_t =  \\phi(X_t) = quantile(X_t) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trends\n",
    "\n",
    "\n",
    "\n",
    "1. ConstantTrend : $$T_t = a $$\n",
    "2. LinearTrend : $$T_t = a t + b$$\n",
    "3. PolyTrend : $$T_t = a t^2 + b t + c$$\n",
    "4. Lag1Trend : $$T_t = Y_t  - Y_{t-1} $$\n",
    "\n",
    "Optional  Models\n",
    "5. MovingAverage : $$T_t = \\sum_{s=t-k}^{s=t-1} Y_s$$\n",
    "5. MovingMedian : $$T_t = median(Y_{t-k}, \\dots, Y_{t-1})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodicities\n",
    "\n",
    "\n",
    "1. None: $$C_t = 0 $$\n",
    "2. BestCycle (extracted automatically) : $$ C_t = C_{t-p}$$\n",
    "3. Seasonality (depends on date parts) : $$ C_t = minute(t) , hour(t), etc$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irregular Components\n",
    "\n",
    "These models are built of the residues of trend and cycles:\n",
    "\n",
    "$$Z_t = Y_t - T_t - C_t $$\n",
    "\n",
    "We consider here some models based on the residue lags ($Lag(Z)_t = Z_{t-k}$).\n",
    "\n",
    "The models described here as implemented using external libraries, either scikit-learn (AR, ARX, SVR) or keras (MLP, LSTM).\n",
    "\n",
    "1. None : $$I_t = 0$$\n",
    "2. Autoregressive (AR) model :  $$I_t = a_0 + \\sum_{k=1}^{k=p} a_k Z_{t-k}$$\n",
    "3. Autoregressive with Exogenous data (ARX) model :  $$I_t = a_0 + \\sum_{k=1}^{k=p} a_k Z_{t-k} + \\sum_{k=1}^{k=p} b_k Exog_{t-k} $$\n",
    "\n",
    "Experimental Models : \n",
    "4. Support Vector Regression  (SVR) : $$I_t = SVR(target = Z_t , inputs = \\{Z_{t-1} , \\dots, Z_{t-p}\\})$$\n",
    "4. MultiLayer Perceptron  (MLP) : $$I_t = MLP(target = Z_t , inputs = \\{Z_{t-1} , \\dots, Z_{t-p}\\})$$\n",
    "4. LSTM : $$I_t = LSTM(target = Z_t , inputs = \\{Z_{t-1} , \\dots, Z_{t-p}\\})$$\n",
    "\n",
    "The parameter $p$ repesents the dependency on the past. It can be customized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP ***************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
